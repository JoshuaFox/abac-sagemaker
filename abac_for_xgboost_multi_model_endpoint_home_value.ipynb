{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8595ec1",
   "metadata": {
    "papermill": {
     "duration": 0.017999,
     "end_time": "2021-05-26T15:52:21.666811",
     "exception": false,
     "start_time": "2021-05-26T15:52:21.648812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attribute-Based Access Control with  Amazon SageMaker Multi-Model Endpoints  \n",
    "This Notebook is based on the [XGBoot Multi-Model example](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/multi_model_xgboost_home_value/xgboost_multi_model_endpoint_home_value.ipynb). Please\n",
    "see that Notebook for details on Multi-Model Endpoint. This one focuses on the ABAC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b393d",
   "metadata": {
    "papermill": {
     "duration": 0.017728,
     "end_time": "2021-05-26T15:52:21.702317",
     "exception": false,
     "start_time": "2021-05-26T15:52:21.684589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Contents\n",
    "\n",
    "1. [Generate synthetic data for housing models](#Generate-synthetic-data-for-housing-models)\n",
    "1. [Train multiple house value prediction models](#Train-multiple-house-value-prediction-models)\n",
    "1. [Create the Amazon SageMaker MultiDataModel entity](#Create-the-Amazon-SageMaker-MultiDataModel-entity)\n",
    "  1. [Create the Multi-Model Endpoint](#Create-the-multi-model-endpoint)\n",
    "  1. [Deploy the Multi-Model Endpoint](#deploy-the-multi-model-endpoint)\n",
    "1. [Get Predictions from the endpoint](#Get-predictions-from-the-endpoint)\n",
    "1. [Additional Information](#Additional-information)\n",
    "1. [Clean up](#Clean-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc8f3e",
   "metadata": {
    "papermill": {
     "duration": 0.017802,
     "end_time": "2021-05-26T15:52:21.738017",
     "exception": false,
     "start_time": "2021-05-26T15:52:21.720215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate synthetic data\n",
    "\n",
    "The code below contains helper functions to generate synthetic data in the form of a `1x7` numpy array representing the features of a house.\n",
    "\n",
    "The first entry in the array is the randomly generated price of a house. The remaining entries are the features (i.e. number of bedroom, square feet, number of bathrooms, etc.).\n",
    "\n",
    "These functions will be used to generate synthetic data for training, validation, and testing. It will also allow us to submit synthetic payloads for inference to test our multi-model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37077e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/abac_multi_model_xgboost_home_value\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20c5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40500513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Execution role for this Notebook arn:aws:iam::649592902942:role/TrackingServiceRole  will assume  arn:aws:iam::649592902942:role/TestInvokeEndpointRole\n"
     ]
    }
   ],
   "source": [
    "# When an endpoint has already been deployed, you can experiment by setting this to False.\n",
    "TRAIN = True\n",
    "print(\"Training\" if TRAIN else \"Not training. Will use existing endpoint\")\n",
    "# We allow invocation of given model in the endpoint only if it matches the tenant. \n",
    "# The model is identified by its filename, so we use that for `TENANT_ID`.\n",
    "\n",
    "TENANT_ID = \"LosAngeles_CA.tar.gz\"\n",
    "\n",
    "account_num = boto3.client('sts').get_caller_identity().get('Account')\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "tenant_role_to_assume = f\"arn:aws:iam::{account_num}:role/TestInvokeEndpointRole\"\n",
    "\n",
    "print('Execution role for this Notebook', role, ' will assume ', tenant_role_to_assume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85461046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:22.030013Z",
     "iopub.status.busy": "2021-05-26T15:52:22.029557Z",
     "iopub.status.idle": "2021-05-26T15:52:22.031372Z",
     "shell.execute_reply": "2021-05-26T15:52:22.031715Z"
    },
    "papermill": {
     "duration": 0.024093,
     "end_time": "2021-05-26T15:52:22.031835",
     "exception": false,
     "start_time": "2021-05-26T15:52:22.007742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_HOUSES_PER_LOCATION = 1000\n",
    "# We use only 4 for testing ABAC, but more are available.\n",
    "LOCATIONS = [\n",
    "     \"NewYork_NY\",\n",
    "     \"LosAngeles_CA\",\n",
    "    \"Chicago_IL\",\n",
    "    \"Houston_TX\",\n",
    "#     \"Dallas_TX\",\n",
    "#     \"Phoenix_AZ\",\n",
    "#     \"Philadelphia_PA\",\n",
    "#     \"SanAntonio_TX\",\n",
    "#     \"SanDiego_CA\",\n",
    "#     \"SanFrancisco_CA\",\n",
    "]\n",
    "PARALLEL_TRAINING_JOBS = 4  # len(LOCATIONS) if your account limits can handle it\n",
    "MAX_YEAR = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7764b775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:22.116765Z",
     "iopub.status.busy": "2021-05-26T15:52:22.116281Z",
     "iopub.status.idle": "2021-05-26T15:52:22.118367Z",
     "shell.execute_reply": "2021-05-26T15:52:22.118004Z"
    },
    "papermill": {
     "duration": 0.025511,
     "end_time": "2021-05-26T15:52:22.118465",
     "exception": false,
     "start_time": "2021-05-26T15:52:22.092954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_price(house):\n",
    "    _base_price = int(house[\"SQUARE_FEET\"] * 150)\n",
    "    _price = int(\n",
    "        _base_price\n",
    "        + (10000 * house[\"NUM_BEDROOMS\"])\n",
    "        + (15000 * house[\"NUM_BATHROOMS\"])\n",
    "        + (15000 * house[\"LOT_ACRES\"])\n",
    "        + (15000 * house[\"GARAGE_SPACES\"])\n",
    "        - (5000 * (MAX_YEAR - house[\"YEAR_BUILT\"]))\n",
    "    )\n",
    "    return _price\n",
    "\n",
    "def gen_random_house():\n",
    "    _house = {\n",
    "        \"SQUARE_FEET\": int(np.random.normal(3000, 750)),\n",
    "        \"NUM_BEDROOMS\": np.random.randint(2, 7),\n",
    "        \"NUM_BATHROOMS\": np.random.randint(2, 7) / 2,\n",
    "        \"LOT_ACRES\": round(np.random.normal(1.0, 0.25), 2),\n",
    "        \"GARAGE_SPACES\": np.random.randint(0, 4),\n",
    "        \"YEAR_BUILT\": min(MAX_YEAR, int(np.random.normal(1995, 10))),\n",
    "    }\n",
    "    _price = gen_price(_house)\n",
    "    return [\n",
    "        _price,\n",
    "        _house[\"YEAR_BUILT\"],\n",
    "        _house[\"SQUARE_FEET\"],\n",
    "        _house[\"NUM_BEDROOMS\"],\n",
    "        _house[\"NUM_BATHROOMS\"],\n",
    "        _house[\"LOT_ACRES\"],\n",
    "        _house[\"GARAGE_SPACES\"],\n",
    "    ]\n",
    "\n",
    "\n",
    "def gen_houses(num_houses):\n",
    "    _house_list = []\n",
    "    for i in range(num_houses):\n",
    "        _house_list.append(gen_random_house())\n",
    "    _df = pd.DataFrame(\n",
    "        _house_list,\n",
    "        columns=[\n",
    "            \"PRICE\",\n",
    "            \"YEAR_BUILT\",\n",
    "            \"SQUARE_FEET\",\n",
    "            \"NUM_BEDROOMS\",\n",
    "            \"NUM_BATHROOMS\",\n",
    "            \"LOT_ACRES\",\n",
    "            \"GARAGE_SPACES\",\n",
    "        ],\n",
    "    )\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02381c4",
   "metadata": {
    "papermill": {
     "duration": 0.018767,
     "end_time": "2021-05-26T15:52:22.198955",
     "exception": false,
     "start_time": "2021-05-26T15:52:22.180188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train multiple house value prediction models\n",
    "\n",
    "We will launch multiple training jobs asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0872c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:22.242238Z",
     "iopub.status.busy": "2021-05-26T15:52:22.241516Z",
     "iopub.status.idle": "2021-05-26T15:52:23.317862Z",
     "shell.execute_reply": "2021-05-26T15:52:23.318235Z"
    },
    "papermill": {
     "duration": 1.100112,
     "end_time": "2021-05-26T15:52:23.318383",
     "exception": false,
     "start_time": "2021-05-26T15:52:22.218271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "import boto3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    " \n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    " \n",
    "print(boto3.Session().region_name)\n",
    "# This is references the AWS managed XGBoost container\n",
    "XGBOOST_IMAGE = image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, framework=\"xgboost\", version=\"1.0-1\"\n",
    ")\n",
    "\n",
    "DATA_PREFIX = \"XGBOOST_BOSTON_HOUSING\"\n",
    "MULTI_MODEL_ARTIFACTS = \"multi_model_artifacts\"\n",
    "\n",
    "TRAIN_INSTANCE_TYPE = \"ml.m4.xlarge\"\n",
    "ENDPOINT_INSTANCE_TYPE = \"ml.m4.xlarge\"\n",
    "\n",
    "ENDPOINT_NAME = \"mme-xgboost-housing1\"\n",
    "\n",
    "MODEL_NAME = ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff37098",
   "metadata": {
    "papermill": {
     "duration": 0.018486,
     "end_time": "2021-05-26T15:52:23.355516",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.337030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split a given dataset into train, validation, and test\n",
    "\n",
    "The code below will generate 3 sets of data. 1 set to train, 1 set for validation and 1 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f3f8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:23.399413Z",
     "iopub.status.busy": "2021-05-26T15:52:23.398931Z",
     "iopub.status.idle": "2021-05-26T15:52:23.400640Z",
     "shell.execute_reply": "2021-05-26T15:52:23.400973Z"
    },
    "papermill": {
     "duration": 0.026957,
     "end_time": "2021-05-26T15:52:23.401092",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.374135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 7\n",
    "SPLIT_RATIOS = [0.6, 0.3, 0.1]\n",
    "\n",
    "\n",
    "def split_data(df):\n",
    "    # split data into train and test sets\n",
    "    seed = SEED\n",
    "    val_size = SPLIT_RATIOS[1]\n",
    "    test_size = SPLIT_RATIOS[2]\n",
    "\n",
    "    num_samples = df.shape[0]\n",
    "    X1 = df.values[:num_samples, 1:]  # keep only the features, skip the target, all rows\n",
    "    Y1 = df.values[:num_samples, :1]  # keep only the target, all rows\n",
    "\n",
    "    # Use split ratios to divide up into train/val/test\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X1, Y1, test_size=(test_size + val_size), random_state=seed\n",
    "    )\n",
    "    # Of the remaining non-training samples, give proper ratio to validation and to test\n",
    "    X_test, X_test, y_test, y_test = train_test_split(\n",
    "        X_val, y_val, test_size=(test_size / (test_size + val_size)), random_state=seed\n",
    "    )\n",
    "    # reassemble the datasets with target in first column and features after that\n",
    "    _train = np.concatenate([y_train, X_train], axis=1)\n",
    "    _val = np.concatenate([y_val, X_val], axis=1)\n",
    "    _test = np.concatenate([y_test, X_test], axis=1)\n",
    "\n",
    "    return _train, _val, _test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33512dbe",
   "metadata": {
    "papermill": {
     "duration": 0.018452,
     "end_time": "2021-05-26T15:52:23.437956",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.419504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Launch a  training job for a given housing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cc166a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:23.492036Z",
     "iopub.status.busy": "2021-05-26T15:52:23.491505Z",
     "iopub.status.idle": "2021-05-26T15:52:23.493365Z",
     "shell.execute_reply": "2021-05-26T15:52:23.493704Z"
    },
    "papermill": {
     "duration": 0.03668,
     "end_time": "2021-05-26T15:52:23.493826",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.457146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_ROUNDS =2 # Set to 25 for better performance. This number is just to save time and cost in testing ABAC.\n",
    "def launch_training_job(location):\n",
    "    # clear out old versions of the data\n",
    "    s3_bucket = s3.Bucket(BUCKET)\n",
    "    full_input_prefix = f\"{DATA_PREFIX}/model_prep/{location}\"\n",
    "    s3_bucket.objects.filter(Prefix=full_input_prefix + \"/\").delete()\n",
    "\n",
    "    # upload the entire set of data for all three channels\n",
    "    local_folder = f\"data/{location}\"\n",
    "    inputs = sagemaker_session.upload_data(path=local_folder, key_prefix=full_input_prefix)\n",
    "    print(f\"Training data uploaded: {inputs}\")\n",
    "\n",
    "    _job = \"xgb-{}\".format(location.replace(\"_\", \"-\"))\n",
    "    full_output_prefix = f\"{DATA_PREFIX}/model_artifacts/{location}\"\n",
    "    s3_output_path = f\"s3://{BUCKET}/{full_output_prefix}\"\n",
    "\n",
    "    xgb = sagemaker.estimator.Estimator(\n",
    "        XGBOOST_IMAGE,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type=TRAIN_INSTANCE_TYPE,\n",
    "        output_path=s3_output_path,\n",
    "        base_job_name=_job,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "\n",
    "    xgb.set_hyperparameters(\n",
    "        max_depth=5,\n",
    "        eta=0.2,\n",
    "        gamma=4,\n",
    "        min_child_weight=6,\n",
    "        subsample=0.8,\n",
    "        silent=0,\n",
    "        early_stopping_rounds=5,\n",
    "        objective=\"reg:linear\",\n",
    "        num_round=NUM_ROUNDS,\n",
    "    )\n",
    "\n",
    "    DISTRIBUTION_MODE = \"FullyReplicated\"\n",
    "\n",
    "    train_input = sagemaker.inputs.TrainingInput(\n",
    "        s3_data=inputs + \"/train\", distribution=DISTRIBUTION_MODE, content_type=\"csv\"\n",
    "    )\n",
    "\n",
    "    val_input = sagemaker.inputs.TrainingInput(\n",
    "        s3_data=inputs + \"/val\", distribution=DISTRIBUTION_MODE, content_type=\"csv\"\n",
    "    )\n",
    "\n",
    "    remote_inputs = {\"train\": train_input, \"validation\": val_input}\n",
    "\n",
    "    xgb.fit(remote_inputs, wait=False)\n",
    "\n",
    "    # Return the estimator object\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f03f35",
   "metadata": {
    "papermill": {
     "duration": 0.018533,
     "end_time": "2021-05-26T15:52:23.531195",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.512662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kick off a model training job for each housing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526d75df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:23.650728Z",
     "iopub.status.busy": "2021-05-26T15:52:23.636764Z",
     "iopub.status.idle": "2021-05-26T15:52:27.820539Z",
     "shell.execute_reply": "2021-05-26T15:52:27.820130Z"
    },
    "papermill": {
     "duration": 4.227067,
     "end_time": "2021-05-26T15:52:27.820645",
     "exception": false,
     "start_time": "2021-05-26T15:52:23.593578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded: s3://sagemaker-us-west-2-649592902942/XGBOOST_BOSTON_HOUSING/model_prep/NewYork_NY\n",
      "Training data uploaded: s3://sagemaker-us-west-2-649592902942/XGBOOST_BOSTON_HOUSING/model_prep/LosAngeles_CA\n",
      "Training data uploaded: s3://sagemaker-us-west-2-649592902942/XGBOOST_BOSTON_HOUSING/model_prep/Chicago_IL\n",
      "Training data uploaded: s3://sagemaker-us-west-2-649592902942/XGBOOST_BOSTON_HOUSING/model_prep/Houston_TX\n",
      "\n",
      "4 training jobs launched: ['xgb-NewYork-NY-2021-08-18-14-32-42-345', 'xgb-LosAngeles-CA-2021-08-18-14-32-43-014', 'xgb-Chicago-IL-2021-08-18-14-32-45-770', 'xgb-Houston-TX-2021-08-18-14-32-47-100']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def save_data_locally(location, train, val, test):\n",
    "    os.makedirs(f\"data/{location}/train\")\n",
    "    np.savetxt(f\"data/{location}/train/{location}_train.csv\", train, delimiter=\",\", fmt=\"%.2f\")\n",
    "\n",
    "    os.makedirs(f\"data/{location}/val\")\n",
    "    np.savetxt(f\"data/{location}/val/{location}_val.csv\", val, delimiter=\",\", fmt=\"%.2f\")\n",
    "\n",
    "    os.makedirs(f\"data/{location}/test\")\n",
    "    np.savetxt(f\"data/{location}/test/{location}_test.csv\", test, delimiter=\",\", fmt=\"%.2f\")\n",
    "estimators = []\n",
    "\n",
    "shutil.rmtree(\"data\", ignore_errors=True)\n",
    "if TRAIN:\n",
    "    for loc in LOCATIONS[:PARALLEL_TRAINING_JOBS]:\n",
    "        _houses = gen_houses(NUM_HOUSES_PER_LOCATION)\n",
    "        _train, _val, _test = split_data(_houses)\n",
    "        save_data_locally(loc, _train, _val, _test)\n",
    "        estimator = launch_training_job(loc)\n",
    "        estimators.append(estimator)\n",
    "\n",
    "print()\n",
    "print(\n",
    "    f\"{len(estimators)} training jobs launched: {[x.latest_training_job.job_name for x in estimators]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de4862b",
   "metadata": {
    "papermill": {
     "duration": 0.019897,
     "end_time": "2021-05-26T15:52:27.860903",
     "exception": false,
     "start_time": "2021-05-26T15:52:27.841006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Wait for all model training to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ba6352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:27.904842Z",
     "iopub.status.busy": "2021-05-26T15:52:27.904334Z",
     "iopub.status.idle": "2021-05-26T15:52:27.906372Z",
     "shell.execute_reply": "2021-05-26T15:52:27.905978Z"
    },
    "papermill": {
     "duration": 0.025948,
     "end_time": "2021-05-26T15:52:27.906472",
     "exception": false,
     "start_time": "2021-05-26T15:52:27.880524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_training_job_to_complete(estimator):\n",
    "    job = estimator.latest_training_job.job_name\n",
    "    print(f\"Waiting for job: {job}\")\n",
    "    status = estimator.latest_training_job.describe()[\"TrainingJobStatus\"]\n",
    "    while status == \"InProgress\":\n",
    "        time.sleep(45)\n",
    "        status = estimator.latest_training_job.describe()[\"TrainingJobStatus\"]\n",
    "        if status == \"InProgress\":\n",
    "            print(f\"{job} job status: {status}\")\n",
    "    print(f\"DONE. Status for {job} is {status}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28dc22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:52:27.950994Z",
     "iopub.status.busy": "2021-05-26T15:52:27.950570Z",
     "iopub.status.idle": "2021-05-26T15:56:58.599409Z",
     "shell.execute_reply": "2021-05-26T15:56:58.599823Z"
    },
    "papermill": {
     "duration": 270.673568,
     "end_time": "2021-05-26T15:56:58.599958",
     "exception": false,
     "start_time": "2021-05-26T15:52:27.926390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job: xgb-NewYork-NY-2021-08-18-14-32-42-345\n",
      "xgb-NewYork-NY-2021-08-18-14-32-42-345 job status: InProgress\n",
      "xgb-NewYork-NY-2021-08-18-14-32-42-345 job status: InProgress\n",
      "xgb-NewYork-NY-2021-08-18-14-32-42-345 job status: InProgress\n",
      "xgb-NewYork-NY-2021-08-18-14-32-42-345 job status: InProgress\n",
      "DONE. Status for xgb-NewYork-NY-2021-08-18-14-32-42-345 is Completed\n",
      "\n",
      "Waiting for job: xgb-LosAngeles-CA-2021-08-18-14-32-43-014\n",
      "DONE. Status for xgb-LosAngeles-CA-2021-08-18-14-32-43-014 is Completed\n",
      "\n",
      "Waiting for job: xgb-Chicago-IL-2021-08-18-14-32-45-770\n",
      "DONE. Status for xgb-Chicago-IL-2021-08-18-14-32-45-770 is Completed\n",
      "\n",
      "Waiting for job: xgb-Houston-TX-2021-08-18-14-32-47-100\n",
      "DONE. Status for xgb-Houston-TX-2021-08-18-14-32-47-100 is Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    for est in estimators:\n",
    "        wait_for_training_job_to_complete(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b5f19",
   "metadata": {
    "papermill": {
     "duration": 0.021394,
     "end_time": "2021-05-26T15:56:58.642731",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.621337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create the multi-model endpoint with the SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c28165",
   "metadata": {
    "papermill": {
     "duration": 0.021378,
     "end_time": "2021-05-26T15:56:58.685363",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.663985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create a SageMaker Model from one of the Estimators\n",
    "\n",
    "The models will be added to the endpoint later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559d56b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:56:58.732555Z",
     "iopub.status.busy": "2021-05-26T15:56:58.732087Z",
     "iopub.status.idle": "2021-05-26T15:56:58.755286Z",
     "shell.execute_reply": "2021-05-26T15:56:58.754836Z"
    },
    "papermill": {
     "duration": 0.048791,
     "end_time": "2021-05-26T15:56:58.755390",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.706599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    estimator = estimators[0]\n",
    "    model = estimator.create_model(role=role, image_uri=XGBOOST_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572b260",
   "metadata": {
    "papermill": {
     "duration": 0.021606,
     "end_time": "2021-05-26T15:56:58.798545",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.776939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create the Amazon SageMaker MultiDataModel entity\n",
    "\n",
    "We create the multi-model endpoint using the [```MultiDataModel```](https://sagemaker.readthedocs.io/en/stable/api/inference/multi_data_model.html) class.\n",
    "\n",
    "We later add more models to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9810295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:56:58.892947Z",
     "iopub.status.busy": "2021-05-26T15:56:58.892485Z",
     "iopub.status.idle": "2021-05-26T15:56:58.894266Z",
     "shell.execute_reply": "2021-05-26T15:56:58.894606Z"
    },
    "papermill": {
     "duration": 0.026415,
     "end_time": "2021-05-26T15:56:58.894726",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.868311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifacts in s3://sagemaker-us-west-2-649592902942/XGBOOST_BOSTON_HOUSING/multi_model_artifacts/\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "\n",
    "# This is where our MME will read models from on S3. The filenames for models that identify the model are for files at this prefix.\n",
    " \n",
    "model_data_prefix = f\"s3://{BUCKET}/{DATA_PREFIX}/{MULTI_MODEL_ARTIFACTS}/\"\n",
    "print( f\"Model artifacts in s3://{BUCKET}/{DATA_PREFIX}/{MULTI_MODEL_ARTIFACTS}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9537ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:56:58.941336Z",
     "iopub.status.busy": "2021-05-26T15:56:58.940878Z",
     "iopub.status.idle": "2021-05-26T15:56:58.946592Z",
     "shell.execute_reply": "2021-05-26T15:56:58.946220Z"
    },
    "papermill": {
     "duration": 0.03048,
     "end_time": "2021-05-26T15:56:58.946693",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.916213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    mme = MultiDataModel(\n",
    "        name=MODEL_NAME,\n",
    "        model_data_prefix=model_data_prefix,\n",
    "        model=model,  # passing our model - passes container image needed for the endpoint\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999e3a2",
   "metadata": {
    "papermill": {
     "duration": 0.021504,
     "end_time": "2021-05-26T15:56:58.989865",
     "exception": false,
     "start_time": "2021-05-26T15:56:58.968361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deploy the Multi Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a2f701c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:56:59.038240Z",
     "iopub.status.busy": "2021-05-26T15:56:59.037801Z",
     "iopub.status.idle": "2021-05-26T16:04:31.002278Z",
     "shell.execute_reply": "2021-05-26T16:04:31.002630Z"
    },
    "papermill": {
     "duration": 451.991333,
     "end_time": "2021-05-26T16:04:31.002783",
     "exception": false,
     "start_time": "2021-05-26T15:56:59.011450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: mme-xgboost-housing1\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-west-2:649592902942:endpoint/mme-xgboost-housing1\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7d66caf275b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     predictor = mme.deploy(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENDPOINT_INSTANCE_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENDPOINT_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/multidatamodel.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         )\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m         self.sagemaker_client.create_endpoint(\n\u001b[0;32m-> 2970\u001b[0;31m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2971\u001b[0m         )\n\u001b[1;32m   2972\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-west-2:649592902942:endpoint/mme-xgboost-housing1\"."
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    predictor = mme.deploy(\n",
    "        initial_instance_count=1, instance_type=ENDPOINT_INSTANCE_TYPE, endpoint_name=ENDPOINT_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa0a7e",
   "metadata": {
    "papermill": {
     "duration": 0.025076,
     "end_time": "2021-05-26T16:04:31.052719",
     "exception": false,
     "start_time": "2021-05-26T16:04:31.027643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Our endpoint has launched\n",
    "\n",
    "Let's look at what models are available to the endpoint.\n",
    "\n",
    "By 'available', what we mean is, what model artfiacts are currently stored under the S3 prefix we defined when setting up the `MultiDataModel` above i.e. `model_data_prefix`.\n",
    "\n",
    "Currently, since we have no artifacts (i.e. `tar.gz` files) stored under  our defined S3 prefix, our endpoint, will have no models 'available' to serve inference requests.\n",
    "\n",
    "We will demonstrate how to make models 'available' to our endpoint below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa0807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:31.113092Z",
     "iopub.status.busy": "2021-05-26T16:04:31.112617Z",
     "iopub.status.idle": "2021-05-26T16:04:31.236757Z",
     "shell.execute_reply": "2021-05-26T16:04:31.236290Z"
    },
    "papermill": {
     "duration": 0.159187,
     "end_time": "2021-05-26T16:04:31.236876",
     "exception": false,
     "start_time": "2021-05-26T16:04:31.077689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    print(\"Models are\", list(mme.list_models()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c30d6",
   "metadata": {
    "papermill": {
     "duration": 0.025501,
     "end_time": "2021-05-26T16:04:31.287713",
     "exception": false,
     "start_time": "2021-05-26T16:04:31.262212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lets deploy model artifacts to be found by the endpoint\n",
    "\n",
    "We are now using the `.add_model()` method of the `MultiDataModel` to copy over our model artifacts from where they were initially stored, during training, to where our endpoint will source model artifacts for inference requests.\n",
    "\n",
    "`model_data_source` refers to the location of our model artifact (i.e. where it was deposited on S3 after training completed)\n",
    "\n",
    "`model_data_path` is the **relative** path to the S3 prefix we specified above (i.e. `model_data_prefix`) where our endpoint will source models for inference requests.\n",
    "\n",
    "Since this is a **relative** path, we can simply pass the name of what we wish to call the model artifact at inference time (i.e. `Chicago_IL.tar.gz`)\n",
    "\n",
    "### Dynamically deploying additional models\n",
    "\n",
    "It is also important to note, that we can always use the `.add_model()` method, as shown below, to dynamically deploy more models to the endpoint, to serve up inference requests as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cced8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:31.343754Z",
     "iopub.status.busy": "2021-05-26T16:04:31.343299Z",
     "iopub.status.idle": "2021-05-26T16:04:32.094101Z",
     "shell.execute_reply": "2021-05-26T16:04:32.094471Z"
    },
    "papermill": {
     "duration": 0.78157,
     "end_time": "2021-05-26T16:04:32.094607",
     "exception": false,
     "start_time": "2021-05-26T16:04:31.313037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    for est in estimators:\n",
    "        artifact_path = est.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "        model_name = artifact_path.split(\"/\")[-4] + \".tar.gz\"\n",
    "        # This is copying over the model artifact to the S3 location for the MME.\n",
    "        mme.add_model(model_data_source=artifact_path, model_data_path=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a539d",
   "metadata": {
    "papermill": {
     "duration": 0.025434,
     "end_time": "2021-05-26T16:04:32.145605",
     "exception": false,
     "start_time": "2021-05-26T16:04:32.120171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We have added the 4 model artifacts from our training jobs!\n",
    "\n",
    "We can see that the S3 prefix we specified when setting up `MultiDataModel` now has 4 model artifacts. As such, the endpoint can now serve up inference requests for these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101c5a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:32.206383Z",
     "iopub.status.busy": "2021-05-26T16:04:32.205867Z",
     "iopub.status.idle": "2021-05-26T16:04:32.335273Z",
     "shell.execute_reply": "2021-05-26T16:04:32.335641Z"
    },
    "papermill": {
     "duration": 0.164864,
     "end_time": "2021-05-26T16:04:32.335776",
     "exception": false,
     "start_time": "2021-05-26T16:04:32.170912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    print(\"Models are\", list(mme.list_models()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207271b9",
   "metadata": {
    "papermill": {
     "duration": 0.025694,
     "end_time": "2021-05-26T16:04:32.387201",
     "exception": false,
     "start_time": "2021-05-26T16:04:32.361507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b84abb",
   "metadata": {
    "papermill": {
     "duration": 0.025813,
     "end_time": "2021-05-26T16:04:32.552226",
     "exception": false,
     "start_time": "2021-05-26T16:04:32.526413",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbc5e00f",
   "metadata": {
    "papermill": {
     "duration": 0.027094,
     "end_time": "2021-05-26T16:04:35.540083",
     "exception": false,
     "start_time": "2021-05-26T16:04:35.512989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using Boto APIs to invoke the endpoint\n",
    "\n",
    "We use the lower level Boto3 SDK, since it is what you would use as a part of a broader architecture.\n",
    "\n",
    "Imagine an API gateway frontend that uses a Lambda Proxy in order to transform request payloads before hitting a SageMaker Endpoint - in this example, Lambda does not have access to the SageMaker Python SDK, and as such, Boto3 can  allow you to interact with your endpoint and serve inference requests.\n",
    "\n",
    "\n",
    "Additional documentation on `.invoke_endpoint()` can be found [here.](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d0849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:35.602663Z",
     "iopub.status.busy": "2021-05-26T16:04:35.602023Z",
     "iopub.status.idle": "2021-05-26T16:04:35.603848Z",
     "shell.execute_reply": "2021-05-26T16:04:35.604194Z"
    },
    "papermill": {
     "duration": 0.037229,
     "end_time": "2021-05-26T16:04:35.604327",
     "exception": false,
     "start_time": "2021-05-26T16:04:35.567098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_temp_tenant_session(access_role_arn, session_name, tenant_id, duration_sec):\n",
    "    \"\"\"\n",
    "    Create a temporary session\n",
    "    :param access_role_arn: The ARN of the role that the caller is assuming\n",
    "    :param session_name: An identifier for the assumed session\n",
    "    :param tenant_id: The tenant identifier the session is created for\n",
    "    :param duration_sec: The duration,in seconds, of the temporary session\n",
    "    :return: The session object that allows you to create service clients and resources\n",
    "    \"\"\"\n",
    "    sts = boto3.client('sts')\n",
    "    print(\"Assuming the access role:\", access_role_arn)\n",
    "    print(\"Tenant ID:\", tenant_id)\n",
    "    assume_role_response = sts.assume_role(\n",
    "        RoleArn=access_role_arn,\n",
    "        DurationSeconds=duration_sec,\n",
    "        RoleSessionName=session_name,\n",
    "        Tags=[\n",
    "            {\n",
    "                'Key': 'TenantID',\n",
    "                'Value': tenant_id\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "     \n",
    "    session = boto3.Session(aws_access_key_id=assume_role_response['Credentials']['AccessKeyId'],\n",
    "                    aws_secret_access_key=assume_role_response['Credentials']['SecretAccessKey'],\n",
    "                    aws_session_token=assume_role_response['Credentials']['SessionToken'])\n",
    "    return session\n",
    "\n",
    "\n",
    "\n",
    "def predict_one_house_value(features, model_name):\n",
    "    print(f\"Using model {model_name}Â±\")\n",
    "\n",
    "    # Notice how we alter the list into a string as the payload\n",
    "    body = \",\".join(map(str, features)) + \"\\n\"\n",
    "\n",
    "    start_time = time.time()\n",
    " \n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME, ContentType=\"text/csv\", TargetModel=model_name, Body=body\n",
    "    )\n",
    "\n",
    "    predicted_value = json.loads(response[\"Body\"].read())[0]\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    print(\"The predicted value was ${:,.2f}\".format(predicted_value))\n",
    "    print(\"{:,d} ms for prediction\".format(int(duration * 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca07a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:35.664075Z",
     "iopub.status.busy": "2021-05-26T16:04:35.663613Z",
     "iopub.status.idle": "2021-05-26T16:04:35.714098Z",
     "shell.execute_reply": "2021-05-26T16:04:35.714450Z"
    },
    "papermill": {
     "duration": 0.082837,
     "end_time": "2021-05-26T16:04:35.714585",
     "exception": false,
     "start_time": "2021-05-26T16:04:35.631748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_session = create_temp_tenant_session(tenant_role_to_assume, \"scoped-session\", TENANT_ID, 900)\n",
    "\n",
    "runtime_sm_client = temp_session.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "# When the model filename equals the tenant ID, invoke_endpoint should pass the IAM check. \n",
    "# Change to \"NewYork_NY.tar.gz\" etc to see the IAM block the invocation.\n",
    "\n",
    "model_filename = TENANT_ID \n",
    "\n",
    "predict_one_house_value(gen_random_house()[1:], model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55687fc8",
   "metadata": {
    "papermill": {
     "duration": 0.027686,
     "end_time": "2021-05-26T16:04:35.769782",
     "exception": false,
     "start_time": "2021-05-26T16:04:35.742096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clean up\n",
    "Here, to be sure we are not billed for endpoints we are no longer using, we clean up.\n",
    "For experimentation, leave `DELETE = False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b3a0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T16:04:35.829381Z",
     "iopub.status.busy": "2021-05-26T16:04:35.828888Z",
     "iopub.status.idle": "2021-05-26T16:04:35.984391Z",
     "shell.execute_reply": "2021-05-26T16:04:35.983963Z"
    },
    "papermill": {
     "duration": 0.187229,
     "end_time": "2021-05-26T16:04:35.984538",
     "exception": false,
     "start_time": "2021-05-26T16:04:35.797309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DELETE = True\n",
    "if DELETE:\n",
    "    deployment_name = ENDPOINT_NAME # Same value used for endpoint and endpoint config\n",
    "\n",
    "    client_del = boto3.client('sagemaker')\n",
    "    response = client_del.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "    variants = response['ProductionVariants']\n",
    "\n",
    "    for v in variants:\n",
    "        model_name = v['ModelName']\n",
    "        client_del.delete_model(ModelName=model_name)    \n",
    "\n",
    "    client_del.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "    client_del.delete_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "    print(\"Done deleting\")\n",
    "else:\n",
    "    print(\"Not deleting resources\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 736.016806,
   "end_time": "2021-05-26T16:04:36.807261",
   "environment_variables": {},
   "exception": true,
   "input_path": "xgboost_multi_model_endpoint_home_value.ipynb",
   "output_path": "/opt/ml/processing/output/xgboost_multi_model_endpoint_home_value-2021-05-26-15-47-56.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-05-26T15:52:20.790455",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
